{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e03f35-ae20-4260-a57d-1bcd882727cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import lightning as L\n",
    "import segmentation_models_pytorch as smp\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from box import Box\n",
    "from config import cfg\n",
    "from dataset import load_datasets\n",
    "from lightning.fabric.fabric import _FabricOptimizer\n",
    "from lightning.fabric.loggers import TensorBoardLogger\n",
    "from losses import DiceLoss\n",
    "from losses import FocalLoss\n",
    "from model import Model\n",
    "from torch.utils.data import DataLoader\n",
    "from utils import AverageMeter\n",
    "from utils import calc_iou\n",
    "\n",
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "\n",
    "def validate(fabric: L.Fabric, model: Model, val_dataloader: DataLoader, epoch: int = 0):\n",
    "    model.eval()\n",
    "    ious = AverageMeter()\n",
    "    f1_scores = AverageMeter()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for iter, data in enumerate(val_dataloader):\n",
    "            images, bboxes, gt_masks = data\n",
    "            num_images = images.size(0)\n",
    "            pred_masks, _ = model(images, bboxes)\n",
    "            for pred_mask, gt_mask in zip(pred_masks, gt_masks):\n",
    "                batch_stats = smp.metrics.get_stats(\n",
    "                    pred_mask,\n",
    "                    gt_mask.int(),\n",
    "                    mode='binary',\n",
    "                    threshold=0.5,\n",
    "                )\n",
    "                batch_iou = smp.metrics.iou_score(*batch_stats, reduction=\"micro-imagewise\")\n",
    "                batch_f1 = smp.metrics.f1_score(*batch_stats, reduction=\"micro-imagewise\")\n",
    "                ious.update(batch_iou, num_images)\n",
    "                f1_scores.update(batch_f1, num_images)\n",
    "            fabric.print(\n",
    "                f'Val: [{epoch}] - [{iter}/{len(val_dataloader)}]: Mean IoU: [{ious.avg:.4f}] -- Mean F1: [{f1_scores.avg:.4f}]'\n",
    "            )\n",
    "\n",
    "    fabric.print(f'Validation [{epoch}]: Mean IoU: [{ious.avg:.4f}] -- Mean F1: [{f1_scores.avg:.4f}]')\n",
    "\n",
    "    fabric.print(f\"Saving checkpoint to {cfg.out_dir}\")\n",
    "    state_dict = model.model.state_dict()\n",
    "    if fabric.global_rank == 0:\n",
    "        torch.save(state_dict, os.path.join(cfg.out_dir, f\"epoch-{epoch:06d}-f1{f1_scores.avg:.2f}-ckpt.pth\"))\n",
    "    model.train()\n",
    "\n",
    "\n",
    "def train_sam(\n",
    "    cfg: Box,\n",
    "    fabric: L.Fabric,\n",
    "    model: Model,\n",
    "    optimizer: _FabricOptimizer,\n",
    "    scheduler: _FabricOptimizer,\n",
    "    train_dataloader: DataLoader,\n",
    "    val_dataloader: DataLoader,\n",
    "):\n",
    "    \"\"\"The SAM training loop.\"\"\"\n",
    "\n",
    "    focal_loss = FocalLoss()\n",
    "    dice_loss = DiceLoss()\n",
    "\n",
    "    for epoch in range(1, cfg.num_epochs):\n",
    "        batch_time = AverageMeter()\n",
    "        data_time = AverageMeter()\n",
    "        focal_losses = AverageMeter()\n",
    "        dice_losses = AverageMeter()\n",
    "        iou_losses = AverageMeter()\n",
    "        total_losses = AverageMeter()\n",
    "        end = time.time()\n",
    "        validated = False\n",
    "\n",
    "        for iter, data in enumerate(train_dataloader):\n",
    "            if epoch > 1 and epoch % cfg.eval_interval == 0 and not validated:\n",
    "                validate(fabric, model, val_dataloader, epoch)\n",
    "                validated = True\n",
    "\n",
    "            data_time.update(time.time() - end)\n",
    "            images, bboxes, gt_masks = data\n",
    "            batch_size = images.size(0)\n",
    "            pred_masks, iou_predictions = model(images, bboxes)\n",
    "            num_masks = sum(len(pred_mask) for pred_mask in pred_masks)\n",
    "            loss_focal = torch.tensor(0., device=fabric.device)\n",
    "            loss_dice = torch.tensor(0., device=fabric.device)\n",
    "            loss_iou = torch.tensor(0., device=fabric.device)\n",
    "            for pred_mask, gt_mask, iou_prediction in zip(pred_masks, gt_masks, iou_predictions):\n",
    "                batch_iou = calc_iou(pred_mask, gt_mask)\n",
    "                loss_focal += focal_loss(pred_mask, gt_mask, num_masks)\n",
    "                loss_dice += dice_loss(pred_mask, gt_mask, num_masks)\n",
    "                loss_iou += F.mse_loss(iou_prediction, batch_iou, reduction='sum') / num_masks\n",
    "\n",
    "            loss_total = 20. * loss_focal + loss_dice + loss_iou\n",
    "            optimizer.zero_grad()\n",
    "            fabric.backward(loss_total)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            focal_losses.update(loss_focal.item(), batch_size)\n",
    "            dice_losses.update(loss_dice.item(), batch_size)\n",
    "            iou_losses.update(loss_iou.item(), batch_size)\n",
    "            total_losses.update(loss_total.item(), batch_size)\n",
    "\n",
    "            fabric.print(f'Epoch: [{epoch}][{iter+1}/{len(train_dataloader)}]'\n",
    "                         f' | Time [{batch_time.val:.3f}s ({batch_time.avg:.3f}s)]'\n",
    "                         f' | Data [{data_time.val:.3f}s ({data_time.avg:.3f}s)]'\n",
    "                         f' | Focal Loss [{focal_losses.val:.4f} ({focal_losses.avg:.4f})]'\n",
    "                         f' | Dice Loss [{dice_losses.val:.4f} ({dice_losses.avg:.4f})]'\n",
    "                         f' | IoU Loss [{iou_losses.val:.4f} ({iou_losses.avg:.4f})]'\n",
    "                         f' | Total Loss [{total_losses.val:.4f} ({total_losses.avg:.4f})]')\n",
    "\n",
    "\n",
    "def configure_opt(cfg: Box, model: Model):\n",
    "\n",
    "    def lr_lambda(step):\n",
    "        if step < cfg.opt.warmup_steps:\n",
    "            return step / cfg.opt.warmup_steps\n",
    "        elif step < cfg.opt.steps[0]:\n",
    "            return 1.0\n",
    "        elif step < cfg.opt.steps[1]:\n",
    "            return 1 / cfg.opt.decay_factor\n",
    "        else:\n",
    "            return 1 / (cfg.opt.decay_factor**2)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.model.parameters(), lr=cfg.opt.learning_rate, weight_decay=cfg.opt.weight_decay)\n",
    "    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
    "\n",
    "    return optimizer, scheduler\n",
    "\n",
    "\n",
    "def main(cfg: Box) -> None:\n",
    "    fabric = L.Fabric(accelerator=\"auto\",\n",
    "                      devices=cfg.num_devices,\n",
    "                      strategy=\"auto\",\n",
    "                      loggers=[TensorBoardLogger(cfg.out_dir, name=\"lightning-sam\")])\n",
    "    fabric.launch()\n",
    "    fabric.seed_everything(1337 + fabric.global_rank)\n",
    "\n",
    "    if fabric.global_rank == 0:\n",
    "        os.makedirs(cfg.out_dir, exist_ok=True)\n",
    "\n",
    "    with fabric.device:\n",
    "        model = Model(cfg)\n",
    "        model.setup()\n",
    "\n",
    "    train_data, val_data = load_datasets(cfg, model.model.image_encoder.img_size)\n",
    "    train_data = fabric._setup_dataloader(train_data)\n",
    "    val_data = fabric._setup_dataloader(val_data)\n",
    "\n",
    "    optimizer, scheduler = configure_opt(cfg, model)\n",
    "    model, optimizer = fabric.setup(model, optimizer)\n",
    "\n",
    "    train_sam(cfg, fabric, model, optimizer, scheduler, train_data, val_data)\n",
    "    validate(fabric, model, val_data, epoch=0)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(cfg)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sam_l",
   "language": "python",
   "name": "sam_l"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
